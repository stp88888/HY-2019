version1 score:0.0951, offline score:0.07245486340462183
version2 score:0.0753, offline score:0.05
version3 score:0.1303, offline:
version4 score:0.1263
version5 score:
version6 score:
version8 score:0.1419
version9 score:0.1423
version10 score:0.1428
version11 score:0.1539
version12 score:
version13 score:0.1539
version14 score:0.1539

version1:协同过滤
version2:邻居选择中去除了自身
version3:邻居选择中加入了自身，加入了按照购买时间的权重计算，更新了相似度计算方式
version4:将购买数量大于50的用户剔除
version5:不剔除用户，使用jaccard相似度计算，更新了相似度计算方式，考虑了热门item，score除以log(1+购买此商品的用户数)
version6:把邻居数量提高至50
version8:获取最近30个item时，将邻居的权重乘以item分数作为排序标准
version9:将用户重复购买的商品强制固定第一位
version10:恢复version4的score计算方式
version11:将用户的30天内购买的item作为结果，缺失值以predict填充（未作前移）
version12:先运行run(version12)，再运行stack(version12)。将用户购买的前5个item作为结果，剩余的以userCF和其他的购买的item交替填充
version13:先运行run(version12)，再运行stack(version13)。将用户购买的前5个item作为结果，剩余的以其他的购买的item和userCF交替填充
version14:先运行run(version12)，再运行stack(version14)。将用户购买的item依次前移作为结果，缺失值以predict填充

应该提高已购买商品的权重
尝试score计算方法：EJ(A,B) = sum ( min(a1, b1) + min (a2, b2)... ) / sum ( max(a1, b1) +max (a2, b2).. )

TODO:
将已购买过的item以irank排序填充NULL？
对异常用户进行过滤，将其于user_item表中剔除(效果不明显，因为购买数量异常的用户作为邻居的分数较低，无法成为近邻)
score计算方式提高已购买商品的score
时间权重是否考虑？(暂时去除)
将用户分为是否重复购买商品的两类，分别进行预测
绝大部分用户都有重复购买的记录，将重复购买的商品置于推荐的前列？

使用GNN进行训练？
SR-GNN论文地址:https://wvvw.aaai.org/ojs/index.php/AAAI/article/view/3804

Q:
程序运行过慢，如何优化？(已解决。1、寻找原始代码中重复计算的项，将其通过dict记录下来，以后如果要用到，直接查询即可，list的查询效率为O(n)，append效率为O(1)，运行时间从2.5h降低至30min。2、在几乎所有查询操作中，将所有的list查询改为set或dict查询，优先set查询，似乎set查询比dict稍快一丢丢？并且将程序运行中的dictionary都通过pickle储存下来，以后如果要使用，直接load即可，运行时间从30min降低至1min。)

pickle模块不可以dump lambda函数(defaultdict中如果使用了lambda，同样不可以，但是可以通过自定义函数来储存defaultdict)

重排序中，如何构建负样本？(尝试方法:针对每一条记录，生成一条负样本记录。1、对用户进行过滤，剔除疑似刷单等异常用户。2、一个userID对应一个itemID，针对itemID的cateID和storeID，进行选择，优先选择cateID与storeID交集的item，其次选择storeID的item，再其次选择cateID的item，最后从所有item中随机选择item作为负样本。)
即使构建完负样本，在缺少用户信息的情况下如何构建模型？

存储大文件时，使用joblib而非pickle，因为pickle在处理大数据时似乎有bug？(https://bugs.python.org/issue24658)，而且joblib对np.array有优化，如果可以的话，尽量使用joblib

np.array比list更加节省内存，原因：因为list中可以存储不同类型的数据，list中存储的是数据的引用地址即指针，那么存储n个数据就需要n个指针和n个数据，而np.array中存储的是相同类型的数据，存储的直接就是数据，因此np.array比list要更省内存，在某些操作中也比list要更高效率。实际中当数据越大，np.array所占的内存为list的一半还少一点，只有当数据极少的时候(甚至list=[i for i in range(10), array=np.array([i for i in range(10)]), array占的内存都比list要少)，list所占内存会比array少。(通过sys.getsizeof()获取对象的内存占用情况)

神经网络中的batch创建部分，可以使用yield使函数变为generator，需要的时候就运行处理一次。

对batch_size处理后剩下的不足batch_size的数据的处理方式:
1、直接抛弃
2、将其直接作为一个batch处理
3、将其参与至下一轮epoch

SR-GNN中，原始序列的长度为n，那么此原始序列可以生成n-1个训练集。

SR-GNN未能提交结果，原因：训练参数不理想导致结果出现明显问题，预测结果全部一样，估计应该调节run_session-gnn中item_least_num和drop_user_limit参数，应提高item_least_num。